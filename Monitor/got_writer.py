"""Persist build_trace payload into got.json via LLM-generated nodes only."""

from __future__ import annotations

import fcntl
import json
import logging
import os
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional

log = logging.getLogger("mcp_tools.monitor")


def _got_session_dir(project_name: str, session_id: str) -> Path:
    return Path(f"/srv/openhands/{project_name}/.openhands/got/{session_id}")


def _load_or_init(got_path: Path) -> Dict[str, Any]:
    try:
        data = json.loads(got_path.read_text(encoding="utf-8"))
    except FileNotFoundError:
        data = {"meta": {}, "nodes": []}
    except json.JSONDecodeError:
        data = {"meta": {}, "nodes": []}

    meta = data.get("meta") or {}
    nodes = data.get("nodes") or []
    if not isinstance(meta, dict):
        meta = {}
    if not isinstance(nodes, list):
        nodes = []

    data["meta"] = meta
    data["nodes"] = nodes
    return data


def _atomic_write_json(path: Path, data: Dict[str, Any]) -> None:
    tmp = path.with_name(f"{path.name}.tmp.{uuid.uuid4()}")
    tmp.write_text(json.dumps(data, ensure_ascii=False), encoding="utf-8")
    with tmp.open("r+") as f:
        f.flush()
        os.fsync(f.fileno())
    os.replace(tmp, path)


async def write_got_from_build_trace(
    *,
    project_name: str,
    session_id: str,
    payload: Dict[str, Any],
) -> Dict[str, Any]:
    """Load got.json, call LLM to generate nodes from subtask (+ artifacts), append, save.

    - Path: /srv/openhands/<project_name>/.openhands/got/<session_id>/got.json
    - Uses fcntl lock.
    """
    from .steps_llm import build_llm_nodes_from_subtask_summary

    session_dir = _got_session_dir(project_name, session_id)
    session_dir.mkdir(parents=True, exist_ok=True)

    got_path = session_dir / "got.json"
    lock_path = session_dir / "got.json.lock"

    with lock_path.open("w") as lock_f:
        fcntl.flock(lock_f.fileno(), fcntl.LOCK_EX)

        got = _load_or_init(got_path)
        meta: Dict[str, Any] = got["meta"]
        nodes: List[Dict[str, Any]] = got["nodes"]

        log.info(
            "got_writer loaded path=%s existing_nodes=%d meta_keys=%s",
            str(got_path),
            len(nodes),
            sorted(list(meta.keys())),
        )

        meta.setdefault("project_name", project_name)
        meta.setdefault("session_id", session_id)


        if not nodes:
            nodes.append(
                {
                    "id": "T001",
                    "title": "Session start",
                    "description": "Root node for this session.",
                    "parents": [{"id": "T001", "relation": "necessitated_by"}],
                }
            )

        steps_dict: Dict[str, Any] = {"meta": meta, "nodes": nodes}
        primary_node_id: Optional[str] = None

        artifacts = payload.get("artifacts")
        if not isinstance(artifacts, list):
            raise ValueError("payload.artifacts must be a list")

        subtask = payload.get("subtask")
        if not isinstance(subtask, dict) or not subtask:
            raise ValueError("payload.subtask is required")

        # Back-compat / boundary validation: depends_on is optional but must be a list of strings if present.
        depends_on = subtask.get("depends_on")
        if depends_on is not None and not (
            isinstance(depends_on, list) and all(isinstance(x, str) for x in depends_on)
        ):
            raise ValueError("subtask.depends_on must be a list of strings")

        log.info(
            "got_writer building nodes from subtask keys=%s artifacts=%d",
            sorted(list(subtask.keys())),
            len(artifacts),
        )

        new_nodes = await build_llm_nodes_from_subtask_summary(
            session_id=session_id,
            subtask=subtask,
            artifacts=artifacts,
            steps=steps_dict,
        )

        log.info("got_writer nodes_from_subtask raw_count=%d", len(new_nodes or []))
        if new_nodes:
            nodes.extend(new_nodes)
            primary_node_id = new_nodes[-1].get("id")
        else:
            log.warning("got_writer no nodes generated by LLM; got.json unchanged except meta")

        log.info(
            "got_writer built nodes_from_subtask added=%d primary_node_id=%s",
            len(new_nodes or []),
            primary_node_id or "",
        )

        if primary_node_id:
            meta["current_focus"] = primary_node_id

        log.info(
            "got_writer writing path=%s total_nodes=%d primary_node_id=%s",
            str(got_path),
            len(nodes),
            primary_node_id or "",
        )
        _atomic_write_json(got_path, got)
        log.info("got_writer write complete path=%s", str(got_path))
        return {
            "status": "ok",
            "primary_node_id": primary_node_id or "",
            "nodes_added": len(new_nodes or []),
            "deduped": False,
        }
